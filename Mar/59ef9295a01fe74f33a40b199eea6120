“The ‘collective West’ continues to support the Kiev regime in fabricating facts about the Russian special operation in Ukraine. Humanity must know the truth,” went a post on the official Twitter account of the Russian Embassy of Egypt, which was published on March 3rd. The tweet included a video showing what appears to be lines of dead bodies covered by tarpaulins. The bodies are being filmed by someone in a yellow jacket. In the foreground, a reporter is talking on camera, when suddenly one of the ‘bodies’ starts moving, and another person runs over to recover them. The message to the viewer is clear: if the “collective West” is paying actors to pretend to be victims of the so-called Russian special military operation, can you trust anything they say? Only, it isn’t clear at all because the video – which was also shared by the official account of the Russian Ministry of Foreign Affairs – has nothing to do with the invasion of Ukraine. It is news footage of a climate change protest in Austria, which was broadcast by OE24.TV last February. For many observers, the fact that it was shared by an official, verified embassy account is a sign of how far-reaching, organised and unscrupulous the information war over Ukraine has become. Razan Ibraheem, a senior editorial analyst with Kinzen, the Irish-based firm which uses humans and technology to track harmful content online as it emerges, cites this example when asked about the role misinformation and propaganda are playing in the war on Ukraine. She spotted the video for a fake immediately because she’d seen it before: it was also recently used by anti-vaxxers to claim that the Covid-19 pandemic was a hoax. Ibraheem, who has been involved in verifying footage from Syria, Afghanistan, Iraq and Yemen since 2015, is stunned by the scale of this information war. “I can’t believe the amount of misinformation on social media across all platforms. The videos are being watched millions of times, and being shared thousands of times on social media. It is across all social media, including TikTok.” How to spot a fake If you don’t want to be an unwitting part of disseminating Russian propaganda, there are a number of steps all social media users and news consumers can follow. 1. Pause before you share. Ibraheem points out the pro-Kremlin accounts are taking examples of (often well-meaning) misinformation in support of Ukraine and using it to back claims that the war is fake news. She cites the example of a video which claimed to show Ukrainian soldiers saying goodbye to their partners and wives and which “is still being shared. It was on social media today. It’s an emotional video that tells a story and fits perfectly with what is happening in Ukraine right now. But the video is from 2017, and it is taken from a trailer for a Ukrainian documentary.” That’s why, she adds, “it is so important to pause. You don’t want to be part of the disinformation phenomenon.” 2. Look for the location, the date and the source of the video. “Go back to the username or the Twitter handle. If you can’t find the original source, don’t share it,” she says. Determining the location requires more patience, but it is possible, as a community of volunteers using Google Maps and open source technology to document the war in real time have shown. “We do an exact match on Google Maps of what we can see in the video. But that’s a complex process,” says Ibraheem. 3. Pay close attention to the details in what you’re looking at. “Make sure this video is representing what it says and the caption matches what is happening in the video,” she suggests. Are there street signs? Distinctive buildings? Shop names? Some videos are easily debunked just by looking at them – she cites the example of videos supposedly coming from Ukraine in which people are dressed in short sleeves. 4. Do a reverse image search. You can do this with a video by taking multiple screenshots. You upload the images, and it will trawl the internet looking to see if it has appeared before. Ibraheem likes Tineye.com. Other tools include Google’s own reverse image tool and the browser extension RevEye. 5. Trust your senses. “Believe in yourself, believe in your ability to try to do your own research,” says Ibraheem. Another clue may be videos that are extremely low resolution, which may mean they have been screengrabbed multiple times. Look for the hashtags associated with misinformation accounts – #RussianTroopsForTruth 6. Know your sources. Share information coming from reliable news outlets, particularly those with journalists on the ground in Ukraine. Imposter accounts are common, so make sure the one you’re retweeting or reposting is who they say they are. And if you’re not, don’t post it. 7. Check if someone else has already verified or debunked the post you’re tempted to share. Associated Press and Reuters run highly regarded fact checking services. Ibraheem mentions voluntary groups such as Bellingcat.com who have become trusted sources for sorting the news from the noise. Another such group is the UK-based Centre for Information Resilience. Misinformation There are different kinds of false or misleading information, and not all is shared with malicious intent. Ibraheem makes a distinction between misinformation and the kind of disinformation being systematically perpetuated by pro-Kremlin forces. Misinformation, she says, is “when people share content without realising that this content is misleading or false.” They may share, she says, because they want to be part of a community or to show their support for the people of Ukraine. But while their intentions are good, “it is misinformation. They are part of the phenomenon.” She gives another example of a viral image that purported to be of a Ukrainian girl injured in the Russian invasion. “In reality, it was actually a Syrian girl.” People share these videos because they have an emotional response to them or because they want to find more followers. “They want to be part of a community experiencing collective emotional support for Ukraine.” Disinformation Disinformation, by contrast, is the creation or sharing of fabricated content with the intention of “having political influence, changing the political narrative, or spreading propaganda.” Much of it is coming from pro-Kremlin forces, and while there is disinformation from the Ukrainian side too, in her experience it is not generally being shared by authorities – or even people in Ukraine. “Both sides are not equal. What you see on the Ukrainian side is people sharing old content, but these people are not generally Ukrainians, they are often supporters in other countries … What we are seeing from the Russian side is an orchestrated campaign, trying to downplay the Russian invasion, change the language around it, suppress information” and manipulate their audience. #OSINT Despite all the negatives of the information war, social media and the internet has simultaneously been playing a crucial positive role in this invasion. A loose, global network of groups and individuals are using technology in real time to locate, analyse and verify acts of aggression and atrocities. This is known as OSINT, or open-source intelligence. The work the OSINT community during the Russian war on Ukraine – possible because it is being uploaded online almost as it happens – rivals massive operations involving huge networks of spies in the past, observers say. It involves trawling social media posts and images to geolocate, analyse and classify them – where it took place; when; who was involved; what kind of weapons were used. This information is stored online in maps and other resources where, many hope, it will be used in the future as a historical resource and to investigate war crimes. The Centre for Information Resilience is mapping OSINT reports of military movements, gunfire, missile attacks, civilian casualties, and destroyed equipment at: maphub.net/Cen4infoRes/russian-ukraine-monitor